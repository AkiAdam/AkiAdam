{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkiAdam/AkiAdam/blob/main/Main_Main1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "nYXvzvi5ZQ_r",
        "outputId": "11bda30e-b1f3-4d39-f76f-78027cc3d3c5"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ac4bf414919b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model = tf.keras.models.load_model('trained_model.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute 'hub'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "#model = tf.keras.models.load_model('trained_model.h5')\n",
        "model = tf.keras.hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n",
        "\n",
        "\n",
        "def estimate_traffic_density(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype('float32')\n",
        "    image = image.reshape(1, 224, 224, 1)\n",
        "    image = image / 255.0\n",
        "    predictions = model.predict(image)\n",
        "    number_of_vehicles = predictions[0][0]\n",
        "    traffic_density = number_of_vehicles / image.shape[2]\n",
        "\n",
        "    return traffic_density\n",
        "\n",
        "\n",
        "#while True:\n",
        "#    image = cv2.VideoCapture(0).read()[1]\n",
        "#    lane1_density = estimate_traffic_density(image[:, 0:400])\n",
        "#    lane2_density = estimate_traffic_density(image[:, 400:800])\n",
        "#    lane3_density = estimate_traffic_density(image[:, 800:1200])\n",
        "\n",
        "#    if lane1_density > lane2_density and lane1_density > lane3_density:\n",
        "#        print(\"lane 1\")# lane 1 is congested\n",
        "#     if lane2_density > lane1_density and lane2_density > lane3_density:\n",
        "#        print(\"lane 2\")# lane 2 is congested\n",
        "#      else:\n",
        "#        print(\"lane 3\")# lane 3 is congested\n",
        "while True:\n",
        "    # Capture an image from the webcam\n",
        "    image = cv2.VideoCapture(0).read()[1]\n",
        "\n",
        "    # Estimate traffic density for each lane\n",
        "    lane1_density = estimate_traffic_density(image[:, 0:400])\n",
        "    lane2_density = estimate_traffic_density(image[:, 400:800])\n",
        "    lane3_density = estimate_traffic_density(image[:, 800:1200])\n",
        "\n",
        "    # Adjust traffic light timings based on traffic density\n",
        "    if lane1_density > lane2_density and lane1_density > lane3_density:\n",
        "        # Give green light to lane 1\n",
        "        print(\"Lane 1 is congested\")\n",
        "    elif lane2_density > lane1_density and lane2_density > lane3_density:\n",
        "        # Give green light to lane 2\n",
        "        print(\"Lane 2 is congested\")\n",
        "    else:\n",
        "        # Give green light to lane 3\n",
        "        print(\"Lane 3 is congested\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoRQrD4ngRm3"
      },
      "source": [
        "Import necessary libraries: The code starts by importing the necessary libraries for image processing (cv2), numerical operations (numpy), and machine learning (tensorflow).\n",
        "\n",
        "Load trained model: The code loads a trained TensorFlow model named trained_model.h5. This model is assumed to be trained to predict the number of vehicles in an image.\n",
        "\n",
        "Define estimate_traffic_density function: This function takes an image as input and performs the following steps:\n",
        "a. Convert the image to grayscale.\n",
        "b. Resize the image to 224x224 pixels.\n",
        "c. Normalize the image pixel values to lie between 0 and 1.\n",
        "d. Reshape the image into a 4D tensor with dimensions (1, 224, 224, 1).\n",
        "e. Feed the image to the trained model and obtain the predicted number of vehicles.\n",
        "f. Calculate the traffic density by dividing the predicted number of vehicles by the image width.\n",
        "g. Return the traffic density.\n",
        "\n",
        "Capture video frames: The code enters a loop that captures frames from the camera using the cv2.VideoCapture() function.\n",
        "\n",
        "Estimate traffic density for each lane: For each frame, the code extracts three 400-pixel-wide lanes from the image and estimates the traffic density for each lane using the estimate_traffic_density() function.\n",
        "\n",
        "Identify congested lane: The code compares the traffic density values for the three lanes and identifies the lane with the highest traffic density.\n",
        "\n",
        "Print congestion message: The code prints a message indicating which lane is congested, based on the identified lane with the highest traffic density.\n",
        "\n",
        "The overall methodology of the code is to capture video frames from a camera, estimate the traffic density for each lane using a trained machine learning model, and identify the most congested lane."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSM27I87d3zZ"
      },
      "source": [
        "modified code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k4DiQJD2dEA",
        "outputId": "89b9dff5-307d-4ed6-f8aa-96c55a2ce04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsaYb4Tmd7jy",
        "outputId": "34ccc26b-4709-4ada-badf-695f22d3c35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to load the image.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained MobilenetV2 model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n",
        "\n",
        "def estimate_traffic_density(image):\n",
        "    # Convert the image to RGB format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to 224x224\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Normalize the image pixel values\n",
        "    image = image.astype('float32')\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Reshape the image to fit the model input\n",
        "    image = image.reshape(1, 224, 224, 3)\n",
        "\n",
        "    # Get the feature vector from the model\n",
        "    features = model(image)\n",
        "\n",
        "    # Extract the number of vehicles from the feature vector\n",
        "    number_of_vehicles = features[0][0]\n",
        "\n",
        "    # Calculate the traffic density\n",
        "    traffic_density = number_of_vehicles / image.shape[2]\n",
        "\n",
        "    return traffic_density\n",
        "\n",
        "# Read an image from file\n",
        "image_path = 'traffic.jpg'\n",
        "input_image = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image was successfully loaded\n",
        "if input_image is None:\n",
        "    print(\"Failed to load the image.\")\n",
        "else:\n",
        "    # Estimate traffic density for each lane\n",
        "    lane1_density = estimate_traffic_density(input_image[:, 0:400])\n",
        "    lane2_density = estimate_traffic_density(input_image[:, 400:800])\n",
        "    lane3_density = estimate_traffic_density(input_image[:, 800:1200])\n",
        "\n",
        "    # Print the traffic density for each lane\n",
        "    print(\"Lane 1 density:\", lane1_density)\n",
        "    print(\"Lane 2 density:\", lane2_density)\n",
        "    print(\"Lane 3 density:\", lane3_density)\n",
        "\n",
        "    # Adjust traffic light timings based on traffic density\n",
        "    if lane1_density > lane2_density and lane1_density > lane3_density:\n",
        "        # Give green light to lane 1\n",
        "        print(\"Lane 1 is congested\")\n",
        "    elif lane2_density > lane1_density and lane2_density > lane3_density:\n",
        "        # Give green light to lane 2\n",
        "        print(\"Lane 2 is congested\")\n",
        "    else:\n",
        "        # Give green light to lane 3\n",
        "        print(\"Lane 3 is congested\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAVwYWUGmlg8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained MobilenetV2 model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n",
        "\n",
        "def estimate_traffic_density(image):\n",
        "    # Convert the image to RGB format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to 224x224\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Normalize the image pixel values\n",
        "    image = image.astype('float32')\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Reshape the image to fit the model input\n",
        "    image = image.reshape(1, 224, 224, 3)\n",
        "\n",
        "    # Get the feature vector from the model\n",
        "    features = model(image)\n",
        "\n",
        "    # Extract the number of vehicles from the feature vector\n",
        "    number_of_vehicles = features[0][0]\n",
        "\n",
        "    # Calculate the traffic density\n",
        "    traffic_density = number_of_vehicles / image.shape[2]\n",
        "\n",
        "    return traffic_density\n",
        "\n",
        "# Read an image from file\n",
        "image_path1 = 'traffic.jpg'\n",
        "input_image1 = cv2.imread(image_path1)\n",
        "image_path2 = 'traffic.jpg'\n",
        "input_image2 = cv2.imread(image_path2)\n",
        "image_path3 = 'traffic.jpg'\n",
        "input_image3 = cv2.imread(image_path3)\n",
        "image_path4 = 'traffic.jpg'\n",
        "input_image4 = cv2.imread(image_path4)\n",
        "\n",
        "# Check if the image was successfully loaded\n",
        "if input_image is None:\n",
        "    print(\"Failed to load the image.\")\n",
        "else:\n",
        "    # Estimate traffic density for each lane\n",
        "    lane1_density = estimate_traffic_density(input_image1)\n",
        "    lane2_density = estimate_traffic_density(input_image2)\n",
        "    lane3_density = estimate_traffic_density(input_image3)\n",
        "\n",
        "\n",
        "    # Print the traffic density for each lane\n",
        "    print(\"Lane 1 density:\", lane1_density)\n",
        "    print(\"Lane 2 density:\", lane2_density)\n",
        "    print(\"Lane 3 density:\", lane3_density)\n",
        "\n",
        " # Find the lane with the highest density\n",
        "    highest_density = max(lane1_density, lane2_density, lane3_density, lane4_density)\n",
        "\n",
        " # Check which lane has the highest density\n",
        "    if lane1_density == highest_density:\n",
        "      print( \"Lane 1 is congested\")\n",
        "    elif lane2_density == highest_density:\n",
        "      print (\"Lane 2 is congested\")\n",
        "    elif lane3_density == highest_density:\n",
        "      print (\"Lane 3 is congested\")\n",
        "    else:\n",
        "      print (\"Lane 4 is congested\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmcabM5rptBV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained MobilenetV2 model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n",
        "\n",
        "def estimate_traffic_density(image):\n",
        "    # Convert the image to RGB format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to 224x224\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Normalize the image pixel values\n",
        "    image = image.astype('float32')\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Reshape the image to fit the model input\n",
        "    image = image.reshape(1, 224, 224, 3)\n",
        "\n",
        "    # Get the feature vector from the model\n",
        "    features = model(image)\n",
        "\n",
        "    # Extract the number of vehicles from the feature vector\n",
        "    number_of_vehicles = features[0][0]\n",
        "\n",
        "    # Calculate the traffic density\n",
        "    traffic_density = number_of_vehicles / image.shape[2]\n",
        "\n",
        "    return traffic_density\n",
        "\n",
        "# Read an image from file\n",
        "image_path1 = 'traffic.jpg'\n",
        "input_image1 = cv2.imread(image_path1)\n",
        "image_path2 = 'traffic.jpg'\n",
        "input_image2 = cv2.imread(image_path2)\n",
        "image_path3 = 'traffic.jpg'\n",
        "input_image3 = cv2.imread(image_path3)\n",
        "image_path4 = 'traffic.jpg'\n",
        "input_image4 = cv2.imread(image_path4)\n",
        "\n",
        "# Check if the image was successfully loaded\n",
        "if input_image is None:\n",
        "    print(\"Failed to load the image.\")\n",
        "else:\n",
        "    # Estimate traffic density for each lane\n",
        "    lane1_density = estimate_traffic_density(input_image1)\n",
        "    lane2_density = estimate_traffic_density(input_image2)\n",
        "    lane3_density = estimate_traffic_density(input_image3)\n",
        "\n",
        "\n",
        "    # Print the traffic density for each lane\n",
        "    print(\"Lane 1 density:\", lane1_density)\n",
        "    print(\"Lane 2 density:\", lane2_density)\n",
        "    print(\"Lane 3 density:\", lane3_density)\n",
        "\n",
        " # Find the lane with the highest density\n",
        "    highest_density = max(lane1_density, lane2_density, lane3_density, lane4_density)\n",
        "\n",
        " # Check which lane has the highest density\n",
        "    if lane1_density == highest_density:\n",
        "      print( \"Lane 1 is congested\")\n",
        "    elif lane2_density == highest_density:\n",
        "      print (\"Lane 2 is congested\")\n",
        "    elif lane3_density == highest_density:\n",
        "      print (\"Lane 3 is congested\")\n",
        "    else:\n",
        "      print (\"Lane 4 is congested\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Rw3CXCpz5_",
        "outputId": "88d8be96-806b-4faa-a9e1-bd179050818e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lane 1 density: tf.Tensor(0.00025396745, shape=(), dtype=float32)\n",
            "Lane 2 density: tf.Tensor(0.0014862355, shape=(), dtype=float32)\n",
            "Lane 3 density: tf.Tensor(0.0006543977, shape=(), dtype=float32)\n",
            "Lane 4 density: tf.Tensor(0.001540746, shape=(), dtype=float32)\n",
            "Lane 4 is congested\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained MobilenetV2 model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n",
        "\n",
        "def estimate_traffic_density(image):\n",
        "    # Convert the image to RGB format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to 224x224\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Normalize the image pixel values\n",
        "    image = image.astype('float32')\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Reshape the image to fit the model input\n",
        "    image = image.reshape(1, 224, 224, 3)\n",
        "\n",
        "    # Get the feature vector from the model\n",
        "    features = model(image)\n",
        "\n",
        "    # Extract the number of vehicles from the feature vector\n",
        "    number_of_vehicles = features[0][0]\n",
        "\n",
        "    # Calculate the traffic density\n",
        "    traffic_density = number_of_vehicles / image.shape[2]\n",
        "\n",
        "    return traffic_density\n",
        "\n",
        "# Read an image from file\n",
        "image_path1 = 'traffic2.jpg'\n",
        "input_image1 = cv2.imread(image_path1)\n",
        "image_path2 = 'traffic1.jpg'\n",
        "input_image2 = cv2.imread(image_path2)\n",
        "image_path3 = 'traffic5.jpg'\n",
        "input_image3 = cv2.imread(image_path3)\n",
        "image_path4 = 'traffic7.jpg'\n",
        "input_image4 = cv2.imread(image_path4)\n",
        "\n",
        "# Check if the image was successfully loaded\n",
        "if input_image1 is None:\n",
        "    print(\"Failed to load the image.\")\n",
        "else:\n",
        "    # Estimate traffic density for each lane\n",
        "    lane1_density = estimate_traffic_density(input_image1)\n",
        "    lane2_density = estimate_traffic_density(input_image2)\n",
        "    lane3_density = estimate_traffic_density(input_image3)\n",
        "    lane4_density = estimate_traffic_density(input_image4)\n",
        "\n",
        "    # Print the traffic density for each lane\n",
        "    print(\"Lane 1 density:\", lane1_density)\n",
        "    print(\"Lane 2 density:\", lane2_density)\n",
        "    print(\"Lane 3 density:\", lane3_density)\n",
        "    print(\"Lane 4 density:\", lane4_density)\n",
        "\n",
        " # Find the lane with the highest density\n",
        "    highest_density = max(lane1_density, lane2_density, lane3_density, lane4_density)\n",
        "\n",
        " # Check which lane has the highest density\n",
        "    if lane1_density == highest_density:\n",
        "      print( \"Lane 1 is congested\")\n",
        "      highest_density = max(lane2_density, lane3_density, lane4_density)\n",
        "      if lane2_density == highest_density:\n",
        "        print (\"Lane 2 is congested\")\n",
        "        if lane3_density>lane4_density:\n",
        "          print (\"Lane 3 is congested\")\n",
        "        else:\n",
        "          print (\"Lane 4 is congested\")\n",
        "      elif lane3_density == highest_density:\n",
        "        print (\"Lane 3 is congested\")\n",
        "        if lane2_density>lane4_density:\n",
        "          print (\"Lane 3 is congested\")\n",
        "        else:\n",
        "          print (\"Lane 4 is congested\")\n",
        "      else:\n",
        "        print (\"Lane 4 is congested\")\n",
        "    elif lane2_density == highest_density:\n",
        "      print (\"Lane 2 is congested\")\n",
        "      highest_density = max(lane1_density, lane3_density, lane4_density)\n",
        "      if lane1_density == highest_density:\n",
        "        print (\"Lane 1 is congested\")\n",
        "        if lane3_density>lane4_density:\n",
        "          print (\"Lane 3 is congested\")\n",
        "        else:\n",
        "          print (\"Lane 4 is congested\")\n",
        "      elif lane3_density == highest_density:\n",
        "        print (\"Lane 3 is congested\")\n",
        "        if lane2_density>lane4_density:\n",
        "          print (\"Lane 3 is congested\")\n",
        "        else:\n",
        "          print (\"Lane 4 is congested\")\n",
        "      else:\n",
        "        print (\"Lane 4 is congested\")\n",
        "    elif lane3_density == highest_density:\n",
        "      print (\"Lane 3 is congested\")\n",
        "      highest_density = max(lane2_density, lane1_density, lane4_density)\n",
        "      if lane2_density == highest_density:\n",
        "        print (\"Lane 2 is congested\")\n",
        "        if lane1_density>lane4_density:\n",
        "          print (\"Lane 3 is congested\")\n",
        "        else:\n",
        "          print (\"Lane 4 is congested\")\n",
        "      elif lane1_density == highest_density:\n",
        "        print (\"Lane 1 is congested\")\n",
        "        if lane2_density>lane4_density:\n",
        "          print (\"Lane 2 is congested\")\n",
        "        else:\n",
        "          print (\"Lane 4 is congested\")\n",
        "      else:\n",
        "        print (\"Lane 4 is congested\")\n",
        "    else:\n",
        "      print (\"Lane 4 is congested\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tchqfEqm80fc",
        "outputId": "2627d941-6a77-4f47-d5ae-a02907f4253d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load the image.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained MobilenetV2 model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n",
        "\n",
        "def estimate_traffic_density(image):\n",
        "    # Convert the image to RGB format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to 224x224\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Normalize the image pixel values\n",
        "    image = image.astype('float32')\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Reshape the image to fit the model input\n",
        "    image = image.reshape(1, 224, 224, 3)\n",
        "\n",
        "    # Get the feature vector from the model\n",
        "    features = model(image)\n",
        "\n",
        "    # Extract the number of vehicles from the feature vector\n",
        "    number_of_vehicles = features[0][0]\n",
        "\n",
        "    # Calculate the traffic density\n",
        "    traffic_density = number_of_vehicles / image.shape[2]\n",
        "\n",
        "    return traffic_density\n",
        "\n",
        "# Read an image from file\n",
        "image_path1 = 'traffic1.jpg'\n",
        "input_image1 = cv2.imread(image_path1)\n",
        "image_path2 = 'traffic2.jpg'\n",
        "input_image2 = cv2.imread(image_path2)\n",
        "image_path3 = 'traffic5.jpg'\n",
        "input_image3 = cv2.imread(image_path3)\n",
        "image_path4 = 'traffic7.jpg'\n",
        "input_image4 = cv2.imread(image_path4)\n",
        "\n",
        "# Check if the image was successfully loaded\n",
        "if input_image1 is None:\n",
        "    print(\"Failed to load the image.\")\n",
        "else:\n",
        "    # Estimate traffic density for each lane\n",
        "    lane1_density = estimate_traffic_density(input_image1)\n",
        "    lane2_density = estimate_traffic_density(input_image2)\n",
        "    lane3_density = estimate_traffic_density(input_image3)\n",
        "    lane4_density = estimate_traffic_density(input_image4)\n",
        "\n",
        "    # Print the traffic density for each lane\n",
        "    print(\"Lane 1 density:\", lane1_density)\n",
        "    print(\"Lane 2 density:\", lane2_density)\n",
        "    print(\"Lane 3 density:\", lane3_density)\n",
        "    print(\"Lane 4 density:\", lane4_density)\n",
        "\n",
        " # Find the lane with the highest density\n",
        "    highest_density = max(lane1_density, lane2_density, lane3_density, lane4_density)\n",
        "\n",
        " # Check which lane has the highest density\n",
        "    if lane1_density == highest_density:\n",
        "      print( \"Lane 1 is congested\")\n",
        "    elif lane2_density == highest_density:\n",
        "      print (\"Lane 2 is congested\")\n",
        "    elif lane3_density == highest_density:\n",
        "      print (\"Lane 3 is congested\")\n",
        "    else:\n",
        "      print (\"Lane 4 is congested\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AooYPZmBgg0V"
      },
      "source": [
        "ambulance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "JmR70L1cgixv",
        "outputId": "9cd39301-66bf-4c83-98dc-a8230c5dc713"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-963b0dbfa4f5>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrained_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/path/to/trained_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_ambulance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /path/to/trained_model.h5"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "trained_model_path = '/path/to/trained_model.h5'\n",
        "\n",
        "model = tf.keras.models.load_model(trained_model_path)\n",
        "\n",
        "def detect_ambulance(image):\n",
        "    # Convert image to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Preprocess image for model\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype('float32')\n",
        "    image = image.reshape(1, 224, 224, 3)\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Predict ambulance\n",
        "    predictions = model.predict(image)\n",
        "    ambulance_present = predictions[0][0] > 0.5\n",
        "\n",
        "    return ambulance_present\n",
        "\n",
        "while True:\n",
        "    # Capture frame from video stream\n",
        "    image = cv2.VideoCapture(0).read()[1]\n",
        "\n",
        "    # Detect ambulance in each lane\n",
        "    lane1_ambulance = detect_ambulance(image[:, 0:400])\n",
        "    lane2_ambulance = detect_ambulance(image[:, 400:800])\n",
        "    lane3_ambulance = detect_ambulance(image[:, 800:1200])\n",
        "\n",
        "    # Print ambulance detection results\n",
        "    if lane1_ambulance:\n",
        "        print(\"lane 1\")\n",
        "    if lane2_ambulance:\n",
        "        print(\"lane 2\")\n",
        "    if lane3_ambulance:\n",
        "        print(\"Ambulance detected in lane 3\")\n",
        "\n",
        "    # Display the captured frame\n",
        "    cv2.imshow('Video Stream', image)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAS4eFF4hvac"
      },
      "source": [
        "Import necessary libraries: The code imports the necessary libraries for image processing (cv2), numerical operations (numpy), and machine learning (tensorflow).\n",
        "\n",
        "Specify trained model path: The code explicitly defines the path to the trained model file trained_model.h5. This ensures that the model is loaded correctly even if it is not located in the current working directory.\n",
        "\n",
        "Load trained model: The code uses the tf.keras.models.load_model() function to load the specified trained model.\n",
        "\n",
        "Define detect_ambulance function: This function takes an image as input and performs the following steps:\n",
        "\n",
        "a. Convert the image to RGB color space.\n",
        "b. Preprocess the image for the model by resizing it, converting it to float32, reshaping it, and normalizing its pixel values.\n",
        "c. Feed the preprocessed image to the trained model and obtain the predicted probability of an ambulance presence.\n",
        "d. Determine whether an ambulance is present based on the probability threshold of 0.5.\n",
        "e. Return a Boolean value indicating whether an ambulance is detected.\n",
        "\n",
        "Capture video frames: The code enters a loop that continuously captures frames from the camera using the cv2.VideoCapture() function.\n",
        "\n",
        "Detect ambulance for each lane: For each captured frame, the code extracts three 400-pixel-wide lanes from the image and checks for the presence of an ambulance in each lane using the detect_ambulance() function.\n",
        "\n",
        "Print ambulance detection results: The code prints a message indicating which lane has an ambulance, if any.\n",
        "\n",
        "Display video stream: The code displays the captured video stream using the cv2.imshow() function.\n",
        "\n",
        "Break loop on 'q' keypress: The loop terminates when the 'q' key is pressed."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}